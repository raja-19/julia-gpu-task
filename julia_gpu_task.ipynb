{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raja-19/julia-gpu-task/blob/main/julia_gpu_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs6rRSq3fDc3"
      },
      "outputs": [],
      "source": [
        "using Pkg\n",
        "Pkg.add(\"BenchmarkTools\")\n",
        "Pkg.add(\"Plots\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using CUDA\n",
        "using BenchmarkTools\n",
        "using Plots\n",
        "using Test"
      ],
      "metadata": {
        "id": "SWoVLTgyzCiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simplicity, I used `arr1` whose vectors and matrices are filled with 1's and `arr2` with 2's."
      ],
      "metadata": {
        "id": "Unq1FCy0UGNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 10\n",
        "n = 2\n",
        "arr1 = fill((fill(1.0f0, n), fill(1.0f0, n, n)), k)\n",
        "arr2 = fill((fill(2.0f0, n), fill(2.0f0, n, n)), k)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JxIxsmnIvMZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CPU"
      ],
      "metadata": {
        "id": "evoHdjMl-OXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First I tried to perform the computation on the CPU. Julia's broadcasting and `map` allow to do that in an elegant way."
      ],
      "metadata": {
        "id": "PGpfUDN5V2If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr3 = map(.+, arr1, arr2)"
      ],
      "metadata": {
        "id": "kKQOj1CeT5Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Julia packages provide a convenient way to do basic unit testing"
      ],
      "metadata": {
        "id": "rf5g1pTeTUP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expected = fill((fill(3.0f0, n), fill(3.0f0, n, n)), k)\n",
        "@test arr3 == expected"
      ],
      "metadata": {
        "id": "xF01UG-k94ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...and benchmarking."
      ],
      "metadata": {
        "id": "4BSh92kRTkjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@btime map(.+, $arr1, $arr2)\n",
        "nothing"
      ],
      "metadata": {
        "id": "1no77sc0949Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPU"
      ],
      "metadata": {
        "id": "iS_p9oSe-h-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Element-wise addition is a simple operation and can be handled by CUDA.jl without the need to write custom kernels. The only challenge is to transform the arrays into a form suitable to be sent to the GPU. Data has to reside in a contiguous block of memory before being sent. I \"flatten\" the inital arrays into 2D arrays of `Float32`'s using `mapreduce` and `hcat` before the computation and go back to the original format after the computation. The postfixes `_h` stands for \"host\" (CPU), and `_d` - for \"device\" (GPU)."
      ],
      "metadata": {
        "id": "76wTR12RV97M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1_h = mapreduce(tup->hcat(tup[1], tup[2]), hcat, arr1)\n",
        "arr2_h = mapreduce(tup->hcat(tup[1], tup[2]), hcat, arr2)\n",
        "arr1_d = CuArray(arr1_h)\n",
        "arr2_d = CuArray(arr2_h)\n",
        "arr3_d = arr1_d + arr2_d\n",
        "arr3_h = Array(arr3_d)\n",
        "arr3 = [(arr3_h[:,i], arr3_h[:,i+1:i+n]) for i in 1:(n+1):size(arr3_h, 2)]"
      ],
      "metadata": {
        "id": "EqIqEBCTxtBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expected = fill((fill(3.0f0, n), fill(3.0f0, n, n)), k)\n",
        "@test arr3 == expected"
      ],
      "metadata": {
        "id": "UxvyZwEI_Us2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@btime CUDA.@sync $arr1_d + $arr2_d\n",
        "nothing"
      ],
      "metadata": {
        "id": "MQsJQ09__XwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For large enough $k$ and $n$, the compuation on the GPU is significantly faster than on the CPU. This is not a fair comparison since the array preprocessing and postprocessing as well as the data transfer are not accounted for. With these factors taken into account, a single element-wise addition is more performant on the CPU."
      ],
      "metadata": {
        "id": "O5nDCwrlaNbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploiting symmetricity on the host"
      ],
      "metadata": {
        "id": "w5frmuSA_m1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried to exploit the fact that the matrices in the arrays are symmetric (as covariance matrices). Thus, the addition can be performed only for their upper triangle parts. The strategy here is to flatten the matrices into 1D arrays using only their upper triangle parts (example below), combine them and the mean vectors into one long array and use that for addition on the GPU.\n",
        "```\n",
        "1 2 3\n",
        "  4 5  ---->  1 2 3 4 5 6\n",
        "    6\n",
        "```"
      ],
      "metadata": {
        "id": "CHJ8d6nlg2uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function sym2flat(S, n)\n",
        "  @inbounds [S[i, j] for i in 1:n for j in i:n]\n",
        "end\n",
        "\n",
        "function flat2sym(a, n)\n",
        "  S = Array{Float32}(undef, n, n)\n",
        "  for i in 1:n\n",
        "    for j in i:n\n",
        "      flatIdx = (i-1)*(2*n-i)÷2+j\n",
        "      @inbounds S[i, j] = S[j, i] = a[flatIdx]\n",
        "    end\n",
        "  end\n",
        "  S\n",
        "end"
      ],
      "metadata": {
        "id": "p_qblCEUBLrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr1_h = mapreduce(tup->vcat(tup[1], sym2flat(tup[2], n)), vcat, arr1)\n",
        "arr2_h = mapreduce(tup->vcat(tup[1], sym2flat(tup[2], n)), vcat, arr2)\n",
        "arr1_d = CuArray(arr1_h)\n",
        "arr2_d = CuArray(arr2_h)\n",
        "arr3_d = arr1_d + arr2_d\n",
        "arr3_h = Array(arr3_d)\n",
        "arr3 = [(arr3_h[1:n], flat2sym(arr3_h[n+1:n*(n+3)÷2], n)) for i in 1:n*(n+3)÷2:length(arr3_h)]"
      ],
      "metadata": {
        "id": "pHdyGawR_Cui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expected = fill((fill(3.0f0, n), fill(3.0f0, n, n)), k)\n",
        "@test arr3 == expected"
      ],
      "metadata": {
        "id": "spPuKwCg_0sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@btime CUDA.@sync $arr1_d + $arr2_d\n",
        "nothing"
      ],
      "metadata": {
        "id": "3pCbYsiW_1Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploiting symmetricity on the device\n",
        "\n"
      ],
      "metadata": {
        "id": "jYUtpyAj_6hQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part was done mostly to just practice writing a custom kernel. Now symmetric elements of a matrix are calculated by the same thread in a way that reduces the number of accesses to the global memory. The data layout is the same as the data layout in the first GPU approach. The implicit layout of the threads is the same as the data layout in the prevous approach. Because these two layouts do not match, careful index mapping is required."
      ],
      "metadata": {
        "id": "MikkzkbRlLDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function add_sym!(arr1_d, arr2_d, arr3_d)\n",
        "  n = size(arr3_d, 1)\n",
        "  k = size(arr3_d, 2) ÷ (n + 1)\n",
        "  start = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
        "  stride = blockDim().x * gridDim().x\n",
        "  tupsize = n * (n + 3) ÷ 2\n",
        "  for idx in start:stride:k*n*(n+3)÷2\n",
        "    tupidx = (idx - 1) ÷ tupsize + 1\n",
        "    tupoffset = (idx - 1) % tupsize + 1\n",
        "    if tupoffset <= n\n",
        "      i = tupoffset\n",
        "      j = (tupidx - 1) * (n + 1) + 1\n",
        "      @inbounds arr3_d[i, j] = arr1_d[i, j] + arr2_d[i, j]\n",
        "    else\n",
        "      matoffset = tupoffset - n\n",
        "      mati = Int(floor((2*n+3-sqrt((2*n+3)^2-8*(n+matoffset)))/2))\n",
        "      matj = matoffset-(mati-1)*(2*n-mati) ÷ 2\n",
        "      i, j = mati, (tupidx - 1) * (n + 1) + 1 + matj\n",
        "      invi, invj = matj, (tupidx - 1) * (n + 1) + 1 + mati\n",
        "      @inbounds arr3_d[invi, invj] = arr3_d[i, j] = arr1_d[i, j] + arr2_d[i, j]\n",
        "    end\n",
        "  end\n",
        "  nothing\n",
        "end"
      ],
      "metadata": {
        "id": "xZj9CU7DXQRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr1_h = mapreduce(tup->hcat(tup[1], tup[2]), hcat, arr1)\n",
        "arr2_h = mapreduce(tup->hcat(tup[1], tup[2]), hcat, arr2)\n",
        "arr1_d = CuArray(arr1_h)\n",
        "arr2_d = CuArray(arr2_h)\n",
        "arr3_d = CuArray{Float32}(undef, n, k*(n+1))\n",
        "\n",
        "nthreads = 1024\n",
        "nblocks = ceil(Int, k*(n*(n+3)÷2)/nthreads)\n",
        "CUDA.@sync @cuda threads=nthreads blocks=nblocks add_sym!(arr1_d, arr2_d, arr3_d)\n",
        "\n",
        "arr3_h = Array(arr3_d)\n",
        "arr3 = [(arr3_h[:,i], arr3_h[:,i+1:i+n]) for i in 1:(n+1):size(arr3_h, 2)]"
      ],
      "metadata": {
        "id": "K7KppwWrV4E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expected = fill((fill(3.0f0, n), fill(3.0f0, n, n)), k)\n",
        "@test arr3 == expected"
      ],
      "metadata": {
        "id": "s9VBPU-XAbCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@btime CUDA.@sync @cuda threads=nthreads blocks=nblocks add_sym!($arr1_d, $arr2_d, $arr3_d)"
      ],
      "metadata": {
        "id": "pUEFQ5-gAdqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For large enough $k$ and $n$, the performance deteriorates even compared to the first GPU approach. The kernel might have become too heavy due to index mapping."
      ],
      "metadata": {
        "id": "86XOoYwnqCvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Benchmarking and visualization"
      ],
      "metadata": {
        "id": "8ExFJgOWBBMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benchmarking is performed for the most promising approach with exploiting symmetricity on the host. Since data preprocessing is quite heavy, the correct data layout in the GPU is hardcoded."
      ],
      "metadata": {
        "id": "fF6gGL-Wp-Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function benchmark_wrapper(k, n)\n",
        "  arr1_d = CUDA.fill(1.0f0, k*n*(n+3)÷2)\n",
        "  arr2_d = CUDA.fill(2.0f0, k*n*(n+3)÷2)\n",
        "  @belapsed CUDA.@sync $arr1_d + $arr2_d\n",
        "end"
      ],
      "metadata": {
        "id": "14d48nAgBLd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ns = [10, 20, 50, 100]\n",
        "ks = [100, 200, 500, 1000]\n",
        "t = [10^6 * benchmark_wrapper(k, n) for k in ks for n in ns]\n",
        "nothing"
      ],
      "metadata": {
        "id": "EZvcHoWKKNZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wireframe(ns, ks, t, xlabel=\"n\", ylabel=\"k\", zlabel=\"time, us\")"
      ],
      "metadata": {
        "id": "qeJK3hh62IT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmesh = reshape(t, length(ns), length(ks))"
      ],
      "metadata": {
        "id": "kKtW5Dfk6frs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "klabels = labels=reshape([\"k=$k\" for k in ks], 1, :)\n",
        "plot(ns, tmesh, marker=:diamond, xlabel=\"n\", ylabel=\"time, us\", labels=klabels)"
      ],
      "metadata": {
        "id": "yGosr_vl0ojn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlabels = labels=reshape([\"n=$n\" for n in ns], 1, :)\n",
        "plot(ks, transpose(tmesh), marker=:diamond, xlabel=\"k\", ylabel=\"time, us\", labels=nlabels)"
      ],
      "metadata": {
        "id": "gTL4mlXA1BGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plots indicate a linear growth with $k$ and a quadratic growth with $n$. Both are expected for large enough $k$ and $n$."
      ],
      "metadata": {
        "id": "moq2JHe8wTw-"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMwp8+H6tKVifARieWlkxeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}